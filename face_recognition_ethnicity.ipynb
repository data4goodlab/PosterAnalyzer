{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNQjq0M0oUov"
   },
   "source": [
    "# Extracting Actor Etnicity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we extract the actors etnicty from the actros photos and match them to movie posters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install of runing on colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWz3mrrgevfJ"
   },
   "outputs": [],
   "source": [
    "!pip install cython\n",
    "\n",
    "!pip install insightface\n",
    "!pip install -U retinaface_pytorch\n",
    "!pip install onnxruntime\n",
    "\n",
    "!pip install opencv-python-headless==4.1.2.30\n",
    "!pip install imagehash\n",
    "!pip install IMDbPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3149,
     "status": "ok",
     "timestamp": 1653336536709,
     "user": {
      "displayName": "Mor Levy",
      "userId": "01162621481807463830"
     },
     "user_tz": -180
    },
    "id": "lfiTU17Fm9TH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'retinaface'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimdb\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Retina Face Model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mretinaface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpre_trained_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Insight Face Model\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minsightface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FaceAnalysis\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'retinaface'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "import imdb\n",
    "\n",
    "# Retina Face Model\n",
    "from retinaface.pre_trained_models import get_model\n",
    "\n",
    "# Insight Face Model\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "from insightface.utils import face_align\n",
    "from insightface.model_zoo import ArcFaceONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eoFZ7wfcnexr"
   },
   "outputs": [],
   "source": [
    "posters_folder = Path('posters')\n",
    "movies_folder = Path('movies')\n",
    "posters_folder.mkdir(exist_ok=True)\n",
    "movies_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iq5UbLfA31Y"
   },
   "source": [
    "# Face Recognition\n",
    "Here we recieve the dataframe after the classification of duplicate posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cTbUn9JJm3D"
   },
   "outputs": [],
   "source": [
    "!unzip actors.zip # the sample'sn actors folder with images \n",
    "!unzip posters.zip # the sample's posters images \n",
    "!unzip movies.zip # the sample's movies metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYjaQUGSCmah"
   },
   "outputs": [],
   "source": [
    "# the base df is posters_with_dup\n",
    "\n",
    "posters_with_dup = pd.read_pickle(\"posters_with_dup.pkl\")\n",
    "posters_df = posters_with_dup[posters_with_dup[\"dups\"] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIyPCk3Om9Vy"
   },
   "source": [
    "## Posters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNjEoeCo0xff",
    "tags": []
   },
   "source": [
    "### Detection\n",
    "Here we detect every face in each poster using RetinFace model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "e58c4cabceeb4e25976d66bb054f67d6",
      "1c8de64f70c34976bb17248da9c1f6f8",
      "83e8f1cdf9c9421d8a63a774c994802d",
      "658bbc9b45e04c17be167f9a601f4169",
      "3169ce5c0b854f46924a797b6b2e0aaa",
      "5beeed0ad00740c886ad3d620676af2f",
      "8f038f394a01412aad9c5e260d77602d",
      "a38656a99be54e70b5fe025dcf0f83dc",
      "9752bd8900664ce9a1ec31cc348b66c8",
      "0acd8788f2d5482287ba0845125704c8",
      "4cfa3a8ebe34478ba0e6dee37f6bb403"
     ]
    },
    "executionInfo": {
     "elapsed": 8007,
     "status": "ok",
     "timestamp": 1647793752023,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "TwSvhHuz6wgX",
    "outputId": "89b96baa-c232-4dfe-e935-392c58494826"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ternaus/retinaface/releases/download/0.01/retinaface_resnet50_2020-07-20-f168fae3c.zip\" to /root/.cache/torch/hub/checkpoints/retinaface_resnet50_2020-07-20-f168fae3c.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58c4cabceeb4e25976d66bb054f67d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/96.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/hub.py:480: UserWarning: Falling back to the old format < 1.6. This support will be deprecated in favor of default zipfile format introduced in 1.6. Please redo torch.save() to save it in the new zipfile format.\n",
      "  warnings.warn('Falling back to the old format < 1.6. This support will be '\n"
     ]
    }
   ],
   "source": [
    "model = get_model(\"resnet50_2020-07-20\", max_size=2048)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 893043,
     "status": "ok",
     "timestamp": 1647794772382,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "tABJLkdi6gki",
    "outputId": "44887f83-3bb4-4351-d245-a3659603cf19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "  2%|▏         | 1/53 [00:17<15:13, 17.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [14:52<00:00, 16.84s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import traceback\n",
    "\n",
    "posters_df['faces'] = ''\n",
    "\n",
    "try:\n",
    "    for row_num, (i, poster_df) in enumerate(tqdm(posters_df.iterrows(), total=len(posters_df))):\n",
    "        image_path = posters_folder / f'{poster_df[\"tconst\"]}{poster_df[\"file_path\"]}'\n",
    "        image = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n",
    "        posters_df.at[i,'faces'] = model.predict_jsons(image)\n",
    "        if row_num % 1000 == 0:\n",
    "            posters_df.to_pickle(\"posters_face_encodings.pkl\") \n",
    "            print('passed', row_num)\n",
    "except Exception as e:\n",
    "    print(traceback.format_exc())\n",
    "    \n",
    "posters_df.to_pickle(\"posters_face_encodings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwPW7rbZ0lhN"
   },
   "source": [
    "### Encoding\n",
    "Here we encode each face detected by RetinaFace using the ArcFace encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha-JLtrtzvsx"
   },
   "outputs": [],
   "source": [
    "posters_face_encodings = pd.read_pickle(\"posters_face_encodings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "od23qNeIu6j2"
   },
   "outputs": [],
   "source": [
    "class ArcFace(ArcFaceONNX):\n",
    "    def get(self, img, landmark):\n",
    "        aimg = face_align.norm_crop(img, landmark=landmark)\n",
    "        return self.get_feat(aimg).flatten()\n",
    "\n",
    "\n",
    "arc = ArcFace(\"w600k_r50.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "985727e7faaf456cb4425c51bdebfa85",
      "9ae2b2230dbe43ebac7706a36528d9af",
      "3c7f6f9a090c4826af4b6f74b1edc803",
      "9660646249384321b81540faf7c65b6b",
      "b610365f5e894ec8a11310fbd6c47742",
      "ca8c6ce931c240ff85816669d31f40c1",
      "49f8a241394e4f5a9af3153ddbf03057",
      "37b6761d860e4616ae3f7dce0a835cc1",
      "3ce011e327fe47ceb8ca7c6ea3232da4",
      "dc16354eb83c4eeabe619d2fc790fe14",
      "70d9829cdba04cb3ad8cb8c981cca3b9"
     ]
    },
    "executionInfo": {
     "elapsed": 18087,
     "status": "ok",
     "timestamp": 1647794911962,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "aEcQzL8uvUt-",
    "outputId": "657bc542-b5c0-46cd-cc79-c9ed70a7d145"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985727e7faaf456cb4425c51bdebfa85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traceback\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "posters_face_encodings[\"embedding\"] = \"\"\n",
    "\n",
    "for row_num, (i, poster_df) in enumerate(tqdm(posters_face_encodings.iterrows(), total=len(posters_face_encodings))):\n",
    "    image_path = posters_folder / f'{poster_df[\"tconst\"]}{poster_df[\"file_path\"]}'\n",
    "\n",
    "    try:\n",
    "        if poster_df[\"embedding\"] == \"\":\n",
    "            img = cv2.imread(str(image_path))\n",
    "            posters_face_encodings.at[i, \"embedding\"] = [\n",
    "                arc.get(img, np.array(f[\"landmarks\"]))\n",
    "                for f in poster_df[\"faces\"]\n",
    "                if f[\"score\"] > 0\n",
    "            ]\n",
    "            if row_num + 1 % 10000 == 0:\n",
    "                posters_face_encodings.to_pickle(\"posters_face_encodings.pkl\")\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "posters_face_encodings.to_pickle(\"posters_face_encodings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-V_TOs9y5GT"
   },
   "source": [
    "## Actors\n",
    "Here we are doing the same process of detection and embeding but for the actors headshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5siKH56aylt6"
   },
   "outputs": [],
   "source": [
    "actors_df = pd.read_pickle('actors_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280062,
     "status": "ok",
     "timestamp": 1647799496085,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "vY31VTArsnvx",
    "outputId": "940b5b80-f64d-4d92-db27-aeeeec719510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_path: /root/.insightface/models/buffalo_l\n",
      "Downloading /root/.insightface/models/buffalo_l.zip from http://insightface.cn-sh2.ufileos.com/models/buffalo_l.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281857/281857 [04:34<00:00, 1026.83KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: /root/.insightface/models/buffalo_l/genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "app = FaceAnalysis(allowed_modules=[\"detection\", \"recognition\"])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203804,
     "status": "ok",
     "timestamp": 1647800108955,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "MdrShhsJzCZL",
    "outputId": "e8019916-e60c-44a6-e32a-f742784a4a65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/359 [00:00<03:56,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 359/359 [03:23<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Actors Insight Face\n",
    "\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "\n",
    "actors_df[\"faces\"] = \"\"\n",
    "\n",
    "try:\n",
    "    for row_num, (i, actor_df) in enumerate(tqdm(actors_df.iterrows(), total=len(actors_df))):\n",
    "        image_path = actor_df[\"img_path\"]\n",
    "        img = cv2.imread(str(image_path))\n",
    "        actors_df.at[i, \"faces\"] = [dict(f) for f in app.get(img)]\n",
    "\n",
    "        if row_num % 10000 == 0:\n",
    "            actors_df.to_pickle(\"actors_face_encodings.pkl\")\n",
    "            print(\"passed\", row_num)\n",
    "\n",
    "except Exception as e:\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "actors_df.to_pickle(\"actors_face_encodings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Tbk-qbGm9V8"
   },
   "source": [
    "## Match Posters Faces With Actors Ids\n",
    "Here we match each face found in the poster to an actor from the movies cast list using a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwU7TKl2uVMu"
   },
   "outputs": [],
   "source": [
    "posters_face_encodings = pd.read_pickle('posters_face_encodings.pkl')\n",
    "actors_face_encodings = pd.read_pickle('actors_face_encodings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9P1VMd2Lud-5"
   },
   "outputs": [],
   "source": [
    "posters_face_encodings  = posters_face_encodings.rename(columns={\"embedding\":\"face_encoding\"})\n",
    "posters_face_encodings[\"boxes\"] = posters_face_encodings[\"faces\"].apply(lambda faces: [f[\"bbox\"] for f in faces])\n",
    "\n",
    "actors_face_encodings[\"face_encoding\"] = actors_face_encodings[\"faces\"].apply(lambda faces: [f[\"embedding\"] for f in faces])\n",
    "actors_face_encodings[\"boxes\"] = actors_face_encodings[\"faces\"].apply(lambda faces: [f[\"bbox\"] for f in faces])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1647800400313,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "MUvgDSPdm9V8",
    "outputId": "160e48f1-0cb2-4f24-b477-79c8ee1e726e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# box = (left, top, right, bottom)\n",
    "MAX_CAST_ACTORS = 1000 # 1000 to get all the cast\n",
    "TOLERANCE = 0.7\n",
    "\n",
    "actors_face_encodings[\"face_size\"] = actors_face_encodings[\"boxes\"].apply(lambda x: [(b - t) * (r - l) for l, t, r, b in x])\n",
    "actors_face_encodings = actors_face_encodings[actors_face_encodings[\"faces\"].apply(lambda x: len(x) != 0)]\n",
    "actors_face_encodings[\"max_face\"] = actors_face_encodings.apply(lambda x: x[\"face_encoding\"][np.argmax(x[\"face_size\"])], axis=1)\n",
    "\n",
    "posters_df = posters_face_encodings[posters_face_encodings[\"face_encoding\"].apply(lambda x: len(x) != 0)]\n",
    "movies = set(posters_df[\"movie\"])\n",
    "\n",
    "posters_df[\"face_actor\"] = \"\"\n",
    "posters_df[\"face_distance\"] = \"\"\n",
    "posters_df[\"face_distance\"] = posters_df[\"face_distance\"].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDyBpQcgQnGt"
   },
   "outputs": [],
   "source": [
    "actors_face_encodings.to_pickle(\"actors_face_encodings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1647800416071,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "VsY3vHPuuxbZ",
    "outputId": "19350f09-300d-4b41-c481-d3a093deebc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1797: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, v, pi)\n",
      "100%|██████████| 3/3 [00:00<00:00,  7.78it/s]\n"
     ]
    }
   ],
   "source": [
    "for movie, posters in tqdm(posters_df.groupby(\"movie\"), total=len(movies)):\n",
    "    try:\n",
    "        with (movies_folder / f'{movie}-{posters[\"tconst\"].iloc[0].lstrip(\"t\")}.pkl').open(\"rb\") as f:\n",
    "            movie_info = pickle.load(f)\n",
    "    except (KeyError, FileNotFoundError):\n",
    "        try:\n",
    "            with next(movies_folder.glob(f'*{posters[\"tconst\"].iloc[0].lstrip(\"t\")}.pkl')).open(\"rb\") as f:\n",
    "                movie_info = pickle.load(f)\n",
    "        except StopIteration:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        cast = movie_info[\"cast\"][:MAX_CAST_ACTORS]\n",
    "        cast_ids = [a.getID() for a in cast]\n",
    "\n",
    "        actors = actors_face_encodings[actors_face_encodings[\"imdb_id\"].isin(cast_ids)]\n",
    "\n",
    "        if len(actors):\n",
    "            for i, p in posters.iterrows():\n",
    "                dist = cdist(np.stack(p[\"face_encoding\"]), np.stack(actors[\"max_face\"].values), metric='cosine')\n",
    "                mins = np.min(dist, 1)\n",
    "\n",
    "                posters_df.loc[i, \"face_distance\"] = [[mins]]\n",
    "                actors_ids = actors.iloc[np.argmin(dist, 1)][\"imdb_id\"].values\n",
    "\n",
    "                matched_actors_ids = [[np.asarray([a[0] if a[1] < TOLERANCE else \"\" for a in zip(actors_ids, mins)],\"object\",)]]\n",
    "\n",
    "                posters_df.loc[i, \"face_actor\"] = matched_actors_ids\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "McSgKBnKKt8l"
   },
   "outputs": [],
   "source": [
    "posters_df.to_pickle(\"match_poster_actor_cast_all.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIV2cOur7gli"
   },
   "source": [
    "# Ethnicity\n",
    "Here we use FairFace model to recognize the actors ethnicity based on 3 headshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_B1Q2FO5RNY"
   },
   "source": [
    "## Predict Actors Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyUa-JhnNt8P"
   },
   "outputs": [],
   "source": [
    "actors_face_encodings = pd.read_pickle('actors_face_encodings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5293,
     "status": "ok",
     "timestamp": 1647800507440,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "CgaFs8-xm9Vf",
    "outputId": "94fd14a2-a0a9-48f8-9d95-d0b2794c75c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FairFace'...\n",
      "remote: Enumerating objects: 220, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 220 (delta 4), reused 1 (delta 0), pack-reused 211\u001b[K\n",
      "Receiving objects: 100% (220/220), 14.23 MiB | 20.07 MiB/s, done.\n",
      "Resolving deltas: 100% (111/111), done.\n",
      "Access denied with the following error:\n",
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1kXdAsqT8YiNYIMm8p5vQUvNFwhBbT4vQ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clone from git and download 4 race model from drive\n",
    "\n",
    "!git clone https://github.com/dchen236/FairFace.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-8m_Vu5kgD_"
   },
   "outputs": [],
   "source": [
    "# download the fairface 4-race model\n",
    "!gdown --id 1kXdAsqT8YiNYIMm8p5vQUvNFwhBbT4vQ\n",
    "\n",
    "# download the fairface 7-race model\n",
    "# !gdown --id 113QMzQzkBDmYMs9LwzvD-jxEZdBQ5J4X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8VrYziPjYqUF"
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import os\n",
    "\n",
    "def get_face(image_path, kps, default_max_size=800,size = 300, padding = 0.25):\n",
    "    \n",
    "    img = dlib.load_rgb_image(str(image_path))\n",
    "\n",
    "    return face_align.norm_crop(img, kps, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEuQ1MMyxTkH"
   },
   "outputs": [],
   "source": [
    "# We adjusted FairFace predict function to exclude 7 races model and image cropping\n",
    "\n",
    "import torch, torchvision \n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predidct_race(save_prediction_at, actors_df):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model_fair_4 = torchvision.models.resnet34(pretrained=True)\n",
    "    model_fair_4.fc = nn.Linear(model_fair_4.fc.in_features, 18)\n",
    "    model_fair_4.load_state_dict(torch.load('res34_fair_align_multi_4_20190809.pt', map_location=torch.device(device)))\n",
    "    model_fair_4 = model_fair_4.to(device)\n",
    "    model_fair_4.eval()\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    face_names = []\n",
    "    race_scores_fair_4 = []\n",
    "    race_preds_fair_4 = []\n",
    "\n",
    "    for index, (_, actor_img) in enumerate(tqdm(actors_df.iterrows(), total=len(actors_df))):\n",
    "\n",
    "        img_path = actor_img[\"img_path\"]\n",
    "        face_names.append(img_path)\n",
    "\n",
    "        kps = actor_img[\"faces\"][0]['kps']  \n",
    "        image = get_face(img_path, kps)\n",
    "        image = trans(image)\n",
    "        image = image.view(1, 3, 224, 224)  # reshape image to match model dimensions (1 batch size)\n",
    "        image = image.to(device) \n",
    "        \n",
    "        # fair 4 class\n",
    "        outputs = model_fair_4(image)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = np.squeeze(outputs)\n",
    "\n",
    "        race_outputs = outputs[:4]\n",
    "        race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "        race_pred = np.argmax(race_score)\n",
    "\n",
    "        race_scores_fair_4.append(race_score)\n",
    "        race_preds_fair_4.append(race_pred)\n",
    "\n",
    "\n",
    "    result = pd.DataFrame([face_names,\n",
    "                           race_preds_fair_4,\n",
    "                           race_scores_fair_4,\n",
    "                         ]).T\n",
    "    result.columns = ['face_name_align',\n",
    "                      # 'race_preds_fair',\n",
    "                      'race_preds_fair_4',\n",
    "                      # 'race_scores_fair',\n",
    "                      'race_scores_fair_4']\n",
    "\n",
    "    # race fair 4\n",
    "\n",
    "    result.loc[result['race_preds_fair_4'] == 0, 'race4'] = 'White'\n",
    "    result.loc[result['race_preds_fair_4'] == 1, 'race4'] = 'Black'\n",
    "    result.loc[result['race_preds_fair_4'] == 2, 'race4'] = 'Asian'\n",
    "    result.loc[result['race_preds_fair_4'] == 3, 'race4'] = 'Indian'\n",
    "\n",
    "    result[['face_name_align',\n",
    "            'race4',\n",
    "            'race_scores_fair_4']].to_csv(save_prediction_at, index=False)\n",
    "\n",
    "    print(\"saved results at \", save_prediction_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcZuQoWtNiYC"
   },
   "outputs": [],
   "source": [
    "predidct_race('races.csv', actors_face_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDMHr8wcx0dh"
   },
   "outputs": [],
   "source": [
    "# Here we recognize and later fillter black&white headshots\n",
    "\n",
    "from PIL import Image, ImageStat\n",
    "def is_grayscale(file, thumb_size=40, MSE_cutoff=22, adjust_color_bias=True):\n",
    "    pil_img = Image.open(file)\n",
    "    bands = pil_img.getbands()\n",
    "    if bands == ('R','G','B') or bands== ('R','G','B','A'):\n",
    "        thumb = pil_img.resize((thumb_size,thumb_size))\n",
    "        SSE, bias = 0, [0,0,0]\n",
    "        if adjust_color_bias:\n",
    "            bias = ImageStat.Stat(thumb).mean[:3]\n",
    "            bias = [b - sum(bias)/3 for b in bias ]\n",
    "        for pixel in thumb.getdata():\n",
    "            mu = sum(pixel)/3\n",
    "            SSE += sum((pixel[i] - mu - bias[i])*(pixel[i] - mu - bias[i]) for i in [0,1,2])\n",
    "        MSE = float(SSE)/(thumb_size*thumb_size)\n",
    "        if MSE <= MSE_cutoff:\n",
    "            return True, MSE\n",
    "        else:\n",
    "            return False, MSE\n",
    "    elif len(bands)==1:\n",
    "        return True, 0\n",
    "    else:\n",
    "        return False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJPPUi80b-wx"
   },
   "outputs": [],
   "source": [
    "races = pd.read_csv('races.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25704,
     "status": "ok",
     "timestamp": 1647800787706,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "bATGhNA9x0dh",
    "outputId": "e58ca02e-7bfb-400b-e6da-661e4a6efd8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 192/356 [00:11<00:10, 14.97it/s]/usr/local/lib/python3.7/dist-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (95727189 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n",
      "100%|██████████| 356/356 [00:25<00:00, 14.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, line in tqdm(races.iterrows(), total=len(races)):\n",
    "    is_grey, mse = is_grayscale(line[\"face_name_align\"])\n",
    "    races.loc[i,\"is_grey\"] = is_grey\n",
    "    races.loc[i,\"mse\"] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaBloTJXchXs"
   },
   "outputs": [],
   "source": [
    "races.to_csv('races.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2fg8a9R5J86"
   },
   "source": [
    "## Connect Faces on Poster to Etnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45iPc2qasQyP"
   },
   "source": [
    "Here we clean the data after prediction and combine it to a large dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUsZaw-Bi5KU"
   },
   "outputs": [],
   "source": [
    "# clean ethnicity data\n",
    "\n",
    "fair_face_outputs = pd.read_csv('races.csv')\n",
    "fair_face_outputs = fair_face_outputs[fair_face_outputs['mse'] > 30]\n",
    "fair_face_outputs = fair_face_outputs[~fair_face_outputs[\"race4\"].isna()]\n",
    "fair_face_outputs[\"id\"] = fair_face_outputs[\"face_name_align\"].apply(lambda x: x.partition(\"actors/\")[2].partition('/')[0])\n",
    "fair_face_outputs[\"imdb_id\"] = fair_face_outputs['id'].str.rpartition(\"-\")[2]\n",
    "fair_face_outputs[\"name\"] = fair_face_outputs['id'].str.rpartition(\"-\")[0]\n",
    "\n",
    "fair_face_outputs[\"race_scores_fair_4\"] = fair_face_outputs[\"race_scores_fair_4\"].str.strip(\"[\")\n",
    "fair_face_outputs[\"race_scores_fair_4\"] = fair_face_outputs[\"race_scores_fair_4\"].str.strip(\"]\")\n",
    "fair_face_outputs[\"race_scores_fair_4\"] = fair_face_outputs[\"race_scores_fair_4\"].str.strip(\" \")\n",
    "\n",
    "fair_face_outputs[\"race_scores_fair_4\"] = fair_face_outputs[\"race_scores_fair_4\"].str.replace(\"\\n\", \"\")\n",
    "fair_face_outputs[\"race_scores_fair_4\"] = fair_face_outputs[\"race_scores_fair_4\"].str.replace(\"  \", \" \")\n",
    "fair_face_outputs[\"race_scores_fair_4\"] = fair_face_outputs[\"race_scores_fair_4\"].str.replace(\"  \", \" \")\n",
    "fair_face_outputs[\"race_scores_fair_4\"] = fair_face_outputs[\"race_scores_fair_4\"].str.replace(\"  \", \" \")\n",
    "\n",
    "fair_face_outputs[[\"White\", \"Black\", \"Asian\", \"Indian\"]] = pd.DataFrame(\n",
    "    fair_face_outputs[\"race_scores_fair_4\"].str.split(\" \", expand=True),\n",
    "    index=fair_face_outputs.index,\n",
    ")\n",
    "\n",
    "fair_face_outputs[\"White\"] = fair_face_outputs[\"White\"].astype(float)\n",
    "fair_face_outputs[\"Black\"] = fair_face_outputs[\"Black\"].astype(float)\n",
    "fair_face_outputs[\"Asian\"] = fair_face_outputs[\"Asian\"].astype(float)\n",
    "fair_face_outputs[\"Indian\"] = fair_face_outputs[\"Indian\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckmLmz5xBayO"
   },
   "outputs": [],
   "source": [
    "ethni_df = fair_face_outputs.groupby(\"imdb_id\").mean().reset_index()\n",
    "ethni_df[\"race\"] = ethni_df[[\"White\", \"Black\", \"Asian\", \"Indian\"]].idxmax(axis=1)\n",
    "ethni_df = ethni_df[[\"imdb_id\", \"race\"]]\n",
    "ethni_df.index = ethni_df.imdb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6NIjOjKCeqn"
   },
   "outputs": [],
   "source": [
    "match_poster_actor = pd.read_pickle(\"match_poster_actor_cast_all.pkl\")\n",
    "\n",
    "match_poster_actor = match_poster_actor[match_poster_actor['face_actor'].apply(lambda x: len(x)>0)]\n",
    "match_poster_actor['face_actor'] = match_poster_actor['face_actor'].apply(lambda x: x[0])\n",
    "match_poster_actor = match_poster_actor[match_poster_actor['face_actor'].apply(lambda x: any(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1647800924714,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "XEa-LDq7l_CV",
    "outputId": "8bac54ba-e32c-4c72-d59f-b0c065d9f382"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 849.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def align_faces_with_ethnicity(row):\n",
    "  return len(row[\"face_actor\"]) == len(row[\"faces\"])\n",
    "\n",
    "match_poster_actor = match_poster_actor[match_poster_actor.apply(align_faces_with_ethnicity, axis=1)]\n",
    "\n",
    "def find_faces_races(row):\n",
    "  races=[]\n",
    "  for imdb_id in row['face_actor']:\n",
    "    try:\n",
    "      values = ethni_df.loc[imdb_id]['race']\n",
    "      races.append(values)\n",
    "    except KeyError:\n",
    "      races.append('')\n",
    "\n",
    "  row['faces_races'] = races\n",
    "  return row\n",
    "\n",
    "posters_races_df = match_poster_actor.apply(find_faces_races, axis=1)\n",
    "\n",
    "\n",
    "def get_races_counts(row):\n",
    "  races=row[\"faces_races\"]\n",
    "\n",
    "  keys = Counter(races).keys()\n",
    "  counts = [100*count/len(races) for count in Counter(races).values()]\n",
    "\n",
    "  for key, count in zip(keys,counts):\n",
    "    row[key] = count\n",
    "\n",
    "  return row\n",
    "\n",
    "posters_races_df = posters_races_df.apply(get_races_counts, axis = 1).fillna(0).drop([''], axis=1)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# images size was reduced during encoding\n",
    "def get_poster_image(movie_title, poster_path):\n",
    "    return Image.open(posters_folder / f\"{movie_title}{poster_path}\")\n",
    "    \n",
    "def calc_new_img_size(row):\n",
    "    poster_img = get_poster_image(row[\"tconst\"], row[\"file_path\"])\n",
    "    w,h = poster_img.size\n",
    "    row['width'] = w\n",
    "    row['height'] = h\n",
    "    \n",
    "    return row\n",
    "\n",
    "posters_races_df = posters_races_df.progress_apply(calc_new_img_size, axis=1)\n",
    "\n",
    "\n",
    "def calc_face_percentage(row):\n",
    "    result = []\n",
    "    for box in row[\"boxes\"]:\n",
    "        l, t, r, b = box\n",
    "        face_size = (b - t) * (r - l)\n",
    "        poster_size = row[\"height\"]*row['width']\n",
    "        result.append( face_size / poster_size )\n",
    "\n",
    "    return result\n",
    "\n",
    "posters_races_df[\"face_percentage\"] = posters_races_df.apply(calc_face_percentage, axis=1)\n",
    "\n",
    "posters_races_df[\"face_percentage_relative\"] = posters_races_df[\"face_percentage\"].apply(lambda row: np.array(row) / max(row))\n",
    "\n",
    "posters_races_df[\"faces_count\"] = posters_races_df[\"faces\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1GZTa0rFDIp"
   },
   "outputs": [],
   "source": [
    "posters_races_df.to_pickle(\"posters_new_races4_cast_all.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMR5qNHpEwiC"
   },
   "source": [
    "## Create Ranking Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7oWln6_shgS"
   },
   "source": [
    "Here we create another dataframe that contains the actor position in the cast list - \"Rank\". \n",
    "\n",
    "We do it for each actor we recognized in the posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1647801007334,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "fOVySSPXEv7O",
    "outputId": "703184ba-50ca-43f7-8299-2abbaa6612a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 72.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_actors_ranking(posters):\n",
    "    movie = posters['movie']\n",
    "    tconst = posters['tconst']\n",
    "    actor_id = posters['face_actor']\n",
    "\n",
    "        \n",
    "    try:\n",
    "        movie_info = pd.read_pickle(movies_folder / f'{movie}-{tconst.lstrip(\"t\")}.pkl')\n",
    "    except (KeyError, FileNotFoundError):\n",
    "        try:\n",
    "            with next(movies_folder.glob(f'*{tconst.lstrip(\"t\")}.pkl')).open(\"rb\") as f:\n",
    "                movie_info = pickle.load(f)\n",
    "        except StopIteration:\n",
    "            print(f'{movie}-{tconst}')\n",
    "            return []\n",
    "                \n",
    "    cast = movie_info['cast']\n",
    "    cast_ids = [a.getID() for a in cast]\n",
    "\n",
    "    posters['actor_rank'] = cast_ids.index(actor_id)+1\n",
    "        \n",
    "    return posters\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "posters_for_ranking_graphs = posters_races_df[['movie', 'startYear', 'tconst', 'face_actor', 'file_path', 'faces_races']].explode('face_actor')\n",
    "posters_for_ranking_graphs['face_race'] = posters_races_df[['movie', 'startYear', 'tconst', 'face_actor', 'file_path', 'faces_races']].explode('faces_races')['faces_races']\n",
    "posters_for_ranking_graphs = posters_for_ranking_graphs[['movie', 'startYear', 'tconst', 'face_actor', 'file_path', 'face_race']]\n",
    "posters_for_ranking_graphs = posters_for_ranking_graphs[posters_for_ranking_graphs['face_actor'] != '']\n",
    "posters_for_ranking_graphs = posters_for_ranking_graphs[posters_for_ranking_graphs['face_race'] != '']\n",
    "posters_for_ranking_graphs = posters_for_ranking_graphs.progress_apply(get_actors_ranking, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDWjN6uBFLEg"
   },
   "outputs": [],
   "source": [
    "posters_for_ranking_graphs.to_pickle(\"ranking_posters_new_races4_cast_all.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EzFjAeF_zWRp"
   ],
   "name": "face_recognition_ethnicity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:posters]",
   "language": "python",
   "name": "conda-env-posters-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0acd8788f2d5482287ba0845125704c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c8de64f70c34976bb17248da9c1f6f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5beeed0ad00740c886ad3d620676af2f",
      "placeholder": "​",
      "style": "IPY_MODEL_8f038f394a01412aad9c5e260d77602d",
      "value": "100%"
     }
    },
    "3169ce5c0b854f46924a797b6b2e0aaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37b6761d860e4616ae3f7dce0a835cc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c7f6f9a090c4826af4b6f74b1edc803": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37b6761d860e4616ae3f7dce0a835cc1",
      "max": 53,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ce011e327fe47ceb8ca7c6ea3232da4",
      "value": 53
     }
    },
    "3ce011e327fe47ceb8ca7c6ea3232da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "49f8a241394e4f5a9af3153ddbf03057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cfa3a8ebe34478ba0e6dee37f6bb403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5beeed0ad00740c886ad3d620676af2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "658bbc9b45e04c17be167f9a601f4169": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0acd8788f2d5482287ba0845125704c8",
      "placeholder": "​",
      "style": "IPY_MODEL_4cfa3a8ebe34478ba0e6dee37f6bb403",
      "value": " 96.9M/96.9M [00:04&lt;00:00, 12.4MB/s]"
     }
    },
    "70d9829cdba04cb3ad8cb8c981cca3b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83e8f1cdf9c9421d8a63a774c994802d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a38656a99be54e70b5fe025dcf0f83dc",
      "max": 101611400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9752bd8900664ce9a1ec31cc348b66c8",
      "value": 101611400
     }
    },
    "8f038f394a01412aad9c5e260d77602d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9660646249384321b81540faf7c65b6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc16354eb83c4eeabe619d2fc790fe14",
      "placeholder": "​",
      "style": "IPY_MODEL_70d9829cdba04cb3ad8cb8c981cca3b9",
      "value": " 53/53 [00:16&lt;00:00,  1.84it/s]"
     }
    },
    "9752bd8900664ce9a1ec31cc348b66c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "985727e7faaf456cb4425c51bdebfa85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ae2b2230dbe43ebac7706a36528d9af",
       "IPY_MODEL_3c7f6f9a090c4826af4b6f74b1edc803",
       "IPY_MODEL_9660646249384321b81540faf7c65b6b"
      ],
      "layout": "IPY_MODEL_b610365f5e894ec8a11310fbd6c47742"
     }
    },
    "9ae2b2230dbe43ebac7706a36528d9af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca8c6ce931c240ff85816669d31f40c1",
      "placeholder": "​",
      "style": "IPY_MODEL_49f8a241394e4f5a9af3153ddbf03057",
      "value": "100%"
     }
    },
    "a38656a99be54e70b5fe025dcf0f83dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b610365f5e894ec8a11310fbd6c47742": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca8c6ce931c240ff85816669d31f40c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc16354eb83c4eeabe619d2fc790fe14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e58c4cabceeb4e25976d66bb054f67d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c8de64f70c34976bb17248da9c1f6f8",
       "IPY_MODEL_83e8f1cdf9c9421d8a63a774c994802d",
       "IPY_MODEL_658bbc9b45e04c17be167f9a601f4169"
      ],
      "layout": "IPY_MODEL_3169ce5c0b854f46924a797b6b2e0aaa"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

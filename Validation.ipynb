{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "an4BoqW1jSBD"
   },
   "source": [
    "# Validation Processes Throught Our Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvEBTdpmn8Jx"
   },
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwCIlJMWm9VR"
   },
   "source": [
    "## Drawing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHfY8n7-m9VR"
   },
   "outputs": [],
   "source": [
    "def get_actor_image(actor_id, actors_df):\n",
    "    return Image.open(actors_df[actors_df[\"imdb_id\"] == actor_id][\"img_path\"].iloc[0])\n",
    "\n",
    "def get_poster_image(movie_title, poster_path):\n",
    "    return Image.open(posters_folder / f\"{movie_title}{poster_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOzvDg6Im9VR"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw \n",
    "\n",
    "def get_image_with_rect(img, box):\n",
    "    #        box = [ l,   t,   r,   d ]\n",
    "    shape = [(box[0], box[1]), (box[2], box[3])]\n",
    "\n",
    "    img1 = ImageDraw.Draw(img)\n",
    "    img1.rectangle(shape, outline=\"red\", width=5)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBeE_d0Tm9VS"
   },
   "outputs": [],
   "source": [
    "def save_as_compared_images(img1, img2, output_name):\n",
    "    size=(500, 500)\n",
    "\n",
    "    img1.thumbnail(size)\n",
    "    img2.thumbnail(size)\n",
    "\n",
    "\n",
    "    images = [img1,img2]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "      new_im.paste(im, (x_offset,0))\n",
    "      x_offset += im.size[0]\n",
    "\n",
    "    new_im.save(f'{output_name}.png')\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ep5Bvhrm9VT"
   },
   "source": [
    "## Manually validate a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujEjF1exm9VW"
   },
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"match_poster_actor_cast_all.pkl\")\n",
    "sample_actors = pd.read_pickle(\"actors_face_encodings.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1647458807163,
     "user": {
      "displayName": "Mor Levy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwyEEZtoAuwpSyqNr_bCxfym7rD3MWVdv2TWWFEQ=s64",
      "userId": "01162621481807463830"
     },
     "user_tz": -120
    },
    "id": "Wm2SnT0Bm9VY",
    "outputId": "420edb97-cc29-4284-aa6f-14d4a945c836"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Desperate Hours',\n",
       "  '/t8iykcGwaH8iK3Zc85VaRg6vlqd.jpg',\n",
       "  '0000620',\n",
       "  [687.72, 549.78, 1020.21, 1011.04]),\n",
       " ('Britt-Marie Was Here',\n",
       "  '/u12KThfDZpBGQ98Qg7ahWvMV9gq.jpg',\n",
       "  '0000278',\n",
       "  [909.25, 175.29, 1132.61, 482.14])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dir_path = 'validation'\n",
    "result = []\n",
    "\n",
    "for i, row in sample.iterrows():\n",
    "    for count, (actor_id, face_location) in enumerate(zip(row[\"face_actor\"][0], row[\"boxes\"])):\n",
    "        if actor_id:\n",
    "            result.append((row[\"movie\"], row[\"file_path\"], actor_id, face_location))\n",
    "            actor_img = get_actor_image(actor_id, sample_actors)\n",
    "            poster_img = get_poster_image(row[\"movie\"], row[\"file_path\"])\n",
    "            poster_img = get_image_with_rect(poster_img, face_location)\n",
    "            save_as_compared_images(actor_img, poster_img, f'{validation_dir_path}/{row[\"movie\"]}-{i}-{actor_id}-{count}')\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYcJ1IVAanWU"
   },
   "source": [
    "## Validate Poster Center Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYkrUdxnat6v"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def draw_center_line(row):\n",
    "  x,y = row['width']/2, row['height']/2\n",
    "  poster_center = (x,y)\n",
    "  boxes = row['boxes']\n",
    "\n",
    "  poster_img = get_poster_image(row[\"movie\"], row[\"file_path\"])\n",
    "  img1 = ImageDraw.Draw(poster_img)\n",
    "\n",
    "  for box in boxes:\n",
    "    (l,t,r,d) = box\n",
    "    face_center = (r-(r-l)/2, d-(d-t)/2)\n",
    "    img1.line([poster_center, face_center], fill=\"red\", width=5)\n",
    "    \n",
    "  return poster_img\n",
    "    \n",
    "draw_center_line(posters_races4_cast_all.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sceSEKuontC"
   },
   "outputs": [],
   "source": [
    "def get_box_size(box):\n",
    "    l,t,r,d = box\n",
    "    return (r-l)*(d-t)\n",
    "    \n",
    "def draw_path_to_largest(img, boxes):\n",
    "\n",
    "    img1 = ImageDraw.Draw(img)\n",
    "    sizes = [get_box_size(b) for b in boxes]\n",
    "    idx_largest = np.argmax(sizes)\n",
    "    l,t,r,d =  boxes[idx_largest]\n",
    "    largest_face_center = (r-(r-l)/2, d-(d-t)/2)\n",
    "    for box in boxes:\n",
    "        (l,t,r,d) = box\n",
    "        face_center = (r-(r-l)/2, d-(d-t)/2)\n",
    "\n",
    "        img1.line((face_center,largest_face_center),  fill=\"red\", width=5)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0C3kp2ybtHg"
   },
   "source": [
    "## Prepare Experiment Of Crime Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1-wJs0Ub6gH"
   },
   "outputs": [],
   "source": [
    "# crime validatin\n",
    "\n",
    "tmdb_data =  pd.read_pickle(metadata_dir/'tmdb_data.pkl', 'rb') \n",
    "en_movies = tmdb_data[tmdb_data['original_language'] == 'en']['imdb_id']\n",
    "\n",
    "def save_images_with_rect(df, output_path):\n",
    "    for i, row in tqdm(df.reset_index().iterrows()):        \n",
    "        img = get_image_with_rect(Image.open(posters_folder / f'{row[\"movie\"]}{row[\"file_path\"]}'), row[\"boxes\"])\n",
    "        img.save(f'{output_path}/{row[\"Decade\"]}{i}{row[\"file_path\"].strip(\"/\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qGVEq4scW0o"
   },
   "outputs": [],
   "source": [
    "LOWER_YEAR_BOUND = 1960\n",
    "UPPER_YEAR_BOUND = 2000\n",
    "NUMBER_OF_SAMPLES = 50\n",
    "\n",
    "sampling_df = posters_new_races4_cast_all.explode([\"boxes\", \"faces_races\",\"face_percentage\"])\n",
    "sampling_df = sampling_df[sampling_df[\"iso_639_1\"] == \"en\"]\n",
    "sampling_df[\"face_percentage\"] = sampling_df[\"face_percentage\"].astype(float)\n",
    "sampling_df = sampling_df[sampling_df[\"faces_races\"]!=\"\"]\n",
    "\n",
    "crime_df = sampling_df[sampling_df.apply(lambda x:  \"Crime\" in x[\"genres\"] , axis=1)]\n",
    "crime_df = crime_df[crime_df[\"face_percentage\"] > sampling_df[\"face_percentage\"].median()]\n",
    "crime_df[\"startYear\"] = crime_df[\"startYear\"].astype(float)\n",
    "crime_df[\"Decade\"] = crime_df[\"startYear\"]//10*10\n",
    "crime_df = crime_df[crime_df[\"tconst\"].isin(en_movies)]\n",
    "\n",
    "for (race, decade), data in crime_df[(crime_df[\"Decade\"]<UPPER_YEAR_BOUND) & (crime_df[\"Decade\"]>=LOWER_YEAR_BOUND)].groupby([\"faces_races\", \"Decade\"]):\n",
    "    if race in ['Asian', 'Indian', 'White', 'Black']: # this line is here for optional sampling from specific races\n",
    "        sampled_posters = data.sample(min([NUMBER_OF_SAMPLES, len(data)]),random_state=42)\n",
    "        out_path = Path(f\"{data_path}/crime/1960_to_2000/{race}\")\n",
    "        out_path.mkdir(exist_ok=True, parents=True)\n",
    "        save_images_with_rect(sampled_posters, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHrKBPXIFUo9"
   },
   "source": [
    "# Ethnicity Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFhCKMbWF3gx"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "base_path = Path ('/content/drive/MyDrive/models/Ethnicity/Results/')\n",
    "races_df = pd.read_csv(base_path / 'races_new4.csv')\n",
    "races_df = races_df[races_df['mse'] > 30]\n",
    "\n",
    "races_df[\"name\"] = races_df[\"face_name_align\"].apply(\n",
    "    lambda x: x.partition(\"actors/\")[2].partition('/')[0].rpartition(\"-\")[0]\n",
    ")\n",
    "\n",
    "ethni4_df = races_df.groupby(\"actor_id\").mean().reset_index()\n",
    "ethni4_df[\"race\"] = ethni4_df[[\"White\", \"Black\", \"Asian\", \"Indian\"]].idxmax(axis=1)\n",
    "ethni4_df = ethni4_df[[\"actor_id\", \"race\"]]\n",
    "ethni4_df = ethni4_df.merge(races_df[['name', 'actor_id']], on='actor_id').drop_duplicates('actor_id')\n",
    "ethni4_df.index = ethni4_df.actor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGA9UWzns8ZF"
   },
   "outputs": [],
   "source": [
    "races7_df = races_df[['race','race_scores_fair', 'actor_id', 'name']]\n",
    "races7_df[\"race_scores_fair\"] = races7_df[\"race_scores_fair\"].str.strip(\"[\")\n",
    "races7_df[\"race_scores_fair\"] = races7_df[\"race_scores_fair\"].str.strip(\"]\")\n",
    "races7_df[\"race_scores_fair\"] = races7_df[\"race_scores_fair\"].str.strip(\" \")\n",
    "\n",
    "races7_df[\"race_scores_fair\"] = races7_df[\"race_scores_fair\"].str.replace(\"\\n\", \"\")\n",
    "races7_df[\"race_scores_fair\"] = races7_df[\"race_scores_fair\"].str.replace(\"  \", \" \")\n",
    "races7_df[\"race_scores_fair\"] = races7_df[\"race_scores_fair\"].str.replace(\"  \", \" \")\n",
    "races7_df[\"race_scores_fair\"] = races7_df[\"race_scores_fair\"].str.replace(\"  \", \" \")\n",
    "\n",
    "\n",
    "races7_df[['White','Black','Latino_Hispanic','East Asian','Southeast Asian','Indian','Middle Eastern']] = pd.DataFrame(\n",
    "    races7_df[\"race_scores_fair\"].str.split(\" \", expand=True),\n",
    "    index=races7_df.index,\n",
    ")\n",
    "races7_df[\"White\"] = races7_df[\"White\"].astype(float)\n",
    "races7_df[\"Black\"] = races7_df[\"Black\"].astype(float)\n",
    "races7_df[\"Latino_Hispanic\"] = races7_df[\"Latino_Hispanic\"].astype(float)\n",
    "races7_df[\"East Asian\"] = races7_df[\"East Asian\"].astype(float)\n",
    "races7_df[\"Southeast Asian\"] = races7_df[\"Southeast Asian\"].astype(float)\n",
    "races7_df[\"Indian\"] = races7_df[\"Indian\"].astype(float)\n",
    "races7_df[\"Middle Eastern\"] = races7_df[\"Middle Eastern\"].astype(float)\n",
    "\n",
    "ethni7_df = races7_df.groupby(\"actor_id\").mean().reset_index()\n",
    "ethni7_df[\"race\"] = ethni7_df[['White','Black','Latino_Hispanic','East Asian','Southeast Asian','Indian','Middle Eastern']].idxmax(axis=1)\n",
    "ethni7_df = ethni7_df[[\"actor_id\", \"race\"]]\n",
    "ethni7_df = ethni7_df.merge(races7_df[['name', 'actor_id']], on='actor_id').drop_duplicates('actor_id')\n",
    "ethni7_df.index = ethni7_df.actor_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92yCOMpiq2vx"
   },
   "outputs": [],
   "source": [
    "# 7 races\n",
    "black = pd.DataFrame({'actor_id':[151,226,291,932,1807,1845,205626,1013003,1569276,2255973],'name': ['Morgan Freeman','Will Smith','Angela Bassett','Halle Berry','Cicely Tyson','Forest Whitaker','Viola Davis','Michael Ealy','Chadwick Boseman','Donald Glover'], 'actual': 'Black'})\n",
    "white = pd.DataFrame({'actor_id':[204,1401,262635,376716,424060,564215,695435,1086543,1165110,1659221],'name': ['Natalie Portman','Angelina Jolie','Chris Evans','Christina Hendricks','Scarlett Johansson','James McAvoy','Chris Pratt','Amanda Seyfried','Chris Hemsworth','Sebastian Stan'], 'actual': 'White'})\n",
    "indian = pd.DataFrame({'actor_id':[821,4626,352032,438463,451234,474774,1229940,1231899,1799038,2138653],'name': ['Amitabh Bachchan','Kareena Kapoor','Kamal Haasan','Anil Kapoor','Irrfan Khan','Akshay Kumar','Katrina Kaif','Priyanka Chopra Jonas','Vidya Balan','Deepika Padukone'], 'actual': 'Indian'})\n",
    "east_asian = pd.DataFrame({'actor_id':[1030205,1402449,2098603,2201753,2347861,2425074,2976916,4081467,4206125,4947538],'name': ['Tôma Ikuta','Sayaka Isoyama','Hikari Mitsushima','Yui Aragaki','Masaki Okada','Ryôsuke Yamada','Kôji Seto','Kento Yamazaki','Nanao','Minami Hamabe'], 'actual': 'East Asian'})\n",
    "southeast_asian = pd.DataFrame({'actor_id':[706,498046,814259,1388074,1787887,1977856,3299397,5377144,6525901,7093076],'name': ['Michelle Yeoh','Reggie Lee','Brenda Song','Tony Jaa','Veronica Ngo','Chin Han','Iko Uwais','Awkwafina','Henry Golding','Lana Condor'], 'actual': 'Southeast Asian'})\n",
    "latino_hispanic = pd.DataFrame({'actor_id':[182,491,973,1507,4851,5527,520064,622897,2201555,4641207],'name': ['Jennifer Lopez','John Leguizamo','Benjamin Bratt','Cheech Marin','Penélope Cruz','Sofía Vergara','George Lopez','Guillermo Navarro','Aubrey Plaza','Jennifer Lopez'], 'actual': 'Latino_Hispanic'})\n",
    "middle_eastern = pd.DataFrame({'actor_id':[1725,267042,452102,869467,1267552,1587232,1840164,1840659,1896736,2316907],'name': ['Omar Sharif','Golshifteh Farahani','Abbas Kiarostami','Shaun Toub','Taraneh Alidoosti','Bahar Soomekh','Ali Saam','Nasim Pedrad','Haaz Sleiman','Yasmine Al Massri'], 'actual': 'Middle Eastern'})\n",
    "actors7_validate = pd.concat([black, white, indian, east_asian, southeast_asian, latino_hispanic, middle_eastern], ignore_index=True)\n",
    "actors7_validate = actors7_validate.merge(ethni7_df[['race']], on='actor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-3z_nGWlbOa"
   },
   "outputs": [],
   "source": [
    "races7 = ['White','Black','Latino_Hispanic','East Asian','Southeast Asian','Indian','Middle Eastern']\n",
    "for race in races7:\n",
    "  df_by_race_precision = actors7_validate[actors7_validate['race'] == race]\n",
    "  df_by_race_recall = actors7_validate[actors7_validate['actual'] == race]\n",
    "  print(f\"{race} Precision - {sum(df_by_race_precision['race'] == df_by_race_precision['actual']) / len(df_by_race_precision) * 100}%\")\n",
    "  print(f\"{race} Recall - {sum(df_by_race_recall['race'] == df_by_race_recall['actual']) / len(df_by_race_recall) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBXHxyROgXpc"
   },
   "outputs": [],
   "source": [
    "# 4 races\n",
    "black = pd.DataFrame({'actor_id':[151,226,291,932,1807,1845,205626,1013003,1569276,2255973],'name': ['Morgan Freeman','Will Smith','Angela Bassett','Halle Berry','Cicely Tyson','Forest Whitaker','Viola Davis','Michael Ealy','Chadwick Boseman','Donald Glover'], 'actual': 'Black'})\n",
    "asian = pd.DataFrame({'actor_id':[2263791,3036914,3254274,3859624,4555391,5377144,6373728,6525901,7093076,7573742],'name': ['Claudia Kim','Arden Cho','Manny Jacinto','Ki Hong Lee','Lyrica Okano','Awkwafina','Ian Chen','Henry Golding','Lana Condor','Ian Chen'], 'actual': 'Asian'})\n",
    "white = pd.DataFrame({'actor_id':[204,1401,262635,376716,424060,564215,695435,1086543,1165110,1659221],'name': ['Natalie Portman','Angelina Jolie','Chris Evans','Christina Hendricks','Scarlett Johansson','James McAvoy','Chris Pratt','Amanda Seyfried','Chris Hemsworth','Sebastian Stan'], 'actual': 'White'})\n",
    "indian = pd.DataFrame({'actor_id':[821,4626,352032,438463,451234,474774,1229940,1231899,1799038,2138653],'name': ['Amitabh Bachchan','Kareena Kapoor','Kamal Haasan','Anil Kapoor','Irrfan Khan','Akshay Kumar','Katrina Kaif','Priyanka Chopra Jonas','Vidya Balan','Deepika Padukone'], 'actual': 'Indian'})\n",
    "actors4_validate = pd.concat([black, asian, white, indian], ignore_index=True)\n",
    "actors4_validate = actors4_validate.merge(ethni4_df[['race']], on='actor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQOiBu_8smT4"
   },
   "outputs": [],
   "source": [
    "races4 = [\"White\", \"Black\", \"Asian\", \"Indian\"]\n",
    "for race in races4:\n",
    "  df_by_race_precision = actors4_validate[actors4_validate['race'] == race]\n",
    "  df_by_race_recall = actors4_validate[actors4_validate['actual'] == race]\n",
    "  print(f\"{race} Precision - {sum(df_by_race_precision['race'] == df_by_race_precision['actual']) / len(df_by_race_precision) * 100}%\")\n",
    "  print(f\"{race} Recall - {sum(df_by_race_recall['race'] == df_by_race_recall['actual']) / len(df_by_race_recall) * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Validation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
